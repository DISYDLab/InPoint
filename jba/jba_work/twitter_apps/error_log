
Logs for container_1625415732249_0006_01_000001
ResourceManager

    RM Home 

NodeManager
Tools
	

SLF4J: Class path contains multiple SLF4J bindings.
SLF4J: Found binding in [jar:file:/usr/local/hadoop_store/tmp/nm-local-dir/filecache/10/spark-libs.jar/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: Found binding in [jar:file:/usr/local/hadoop/share/hadoop/common/lib/slf4j-log4j12-1.7.25.jar!/org/slf4j/impl/StaticLoggerBinder.class]
SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.
SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]
21/07/05 00:23:06 INFO SignalUtils: Registered signal handler for TERM
21/07/05 00:23:06 INFO SignalUtils: Registered signal handler for HUP
21/07/05 00:23:06 INFO SignalUtils: Registered signal handler for INT
21/07/05 00:23:06 INFO SecurityManager: Changing view acls to: hadoopuser
21/07/05 00:23:06 INFO SecurityManager: Changing modify acls to: hadoopuser
21/07/05 00:23:06 INFO SecurityManager: Changing view acls groups to: 
21/07/05 00:23:06 INFO SecurityManager: Changing modify acls groups to: 
21/07/05 00:23:06 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(hadoopuser); groups with view permissions: Set(); users  with modify permissions: Set(hadoopuser); groups with modify permissions: Set()
21/07/05 00:23:07 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
21/07/05 00:23:07 INFO ApplicationMaster: ApplicationAttemptId: appattempt_1625415732249_0006_000001
21/07/05 00:23:07 INFO RMProxy: Connecting to ResourceManager at master/10.10.14.100:8030
21/07/05 00:23:07 INFO YarnRMClient: Registering the ApplicationMaster
21/07/05 00:23:07 INFO TransportClientFactory: Successfully created connection to spark-client/10.10.14.110:34143 after 47 ms (0 ms spent in bootstraps)
21/07/05 00:23:07 INFO ApplicationMaster: Preparing Local resources
21/07/05 00:23:08 INFO ApplicationMaster: 
===============================================================================
Default YARN executor launch context:
  env:
    CLASSPATH -> {{PWD}}<CPS>{{PWD}}/__spark_conf__<CPS>{{PWD}}/__spark_libs__/*<CPS>$HADOOP_CONF_DIR<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/*<CPS>$HADOOP_COMMON_HOME/share/hadoop/common/lib/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/*<CPS>$HADOOP_HDFS_HOME/share/hadoop/hdfs/lib/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/*<CPS>$HADOOP_YARN_HOME/share/hadoop/yarn/lib/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*<CPS>$HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*<CPS>{{PWD}}/__spark_conf__/__hadoop_conf__
    SPARK_YARN_STAGING_DIR -> hdfs://master:9000/user/hadoopuser/.sparkStaging/application_1625415732249_0006
    SPARK_USER -> hadoopuser
    PYTHONPATH -> {{PWD}}/pyspark.zip<CPS>{{PWD}}/py4j-0.10.9-src.zip

  command:
    {{JAVA_HOME}}/bin/java \ 
      -server \ 
      -Xmx4608m \ 
      -Djava.io.tmpdir={{PWD}}/tmp \ 
      '-Dspark.driver.port=34143' \ 
      -Dspark.yarn.app.container.log.dir=<LOG_DIR> \ 
      -XX:OnOutOfMemoryError='kill %p' \ 
      org.apache.spark.executor.YarnCoarseGrainedExecutorBackend \ 
      --driver-url \ 
      spark://CoarseGrainedScheduler@spark-client:34143 \ 
      --executor-id \ 
      <executorId> \ 
      --hostname \ 
      <hostname> \ 
      --cores \ 
      1 \ 
      --app-id \ 
      application_1625415732249_0006 \ 
      --resourceProfileId \ 
      0 \ 
      --user-class-path \ 
      file:$PWD/__app__.jar \ 
      1><LOG_DIR>/stdout \ 
      2><LOG_DIR>/stderr

  resources:
    pyspark.zip -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/hadoopuser/.sparkStaging/application_1625415732249_0006/pyspark.zip" } size: 728482 timestamp: 1625433784986 type: FILE visibility: PRIVATE
    __spark_libs__ -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/hadoopuser/spark-jars-3.0.0/spark-libs.jar" } size: 225869710 timestamp: 1624883112375 type: ARCHIVE visibility: PUBLIC
    py4j-0.10.9-src.zip -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/hadoopuser/.sparkStaging/application_1625415732249_0006/py4j-0.10.9-src.zip" } size: 41587 timestamp: 1625433785105 type: FILE visibility: PRIVATE
    __spark_conf__ -> resource { scheme: "hdfs" host: "master" port: 9000 file: "/user/hadoopuser/.sparkStaging/application_1625415732249_0006/__spark_conf__.zip" } size: 320962 timestamp: 1625433785628 type: ARCHIVE visibility: PRIVATE

===============================================================================
21/07/05 00:23:08 INFO Configuration: resource-types.xml not found
21/07/05 00:23:08 INFO ResourceUtils: Unable to find 'resource-types.xml'.
21/07/05 00:23:08 INFO YarnAllocator: Will request 24 executor container(s), each with 1 core(s) and 5068 MB memory (including 460 MB of overhead)
21/07/05 00:23:08 INFO YarnAllocator: Submitted 24 unlocalized container requests.
21/07/05 00:23:08 INFO ApplicationMaster: Started progress reporter thread with (heartbeat : 3000, initial allocation : 200) intervals
21/07/05 00:23:08 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000002 on host slave1 for executor with ID 1
21/07/05 00:23:08 INFO YarnAllocator: Received 1 containers from YARN, launching executors on 1 of them.
21/07/05 00:23:09 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000003 on host slave5 for executor with ID 2
21/07/05 00:23:09 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000004 on host slave6 for executor with ID 3
21/07/05 00:23:09 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000005 on host slave4 for executor with ID 4
21/07/05 00:23:09 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000006 on host slave3 for executor with ID 5
21/07/05 00:23:09 INFO YarnAllocator: Received 4 containers from YARN, launching executors on 4 of them.
21/07/05 00:23:09 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000007 on host slave2 for executor with ID 6
21/07/05 00:23:09 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000008 on host slave1 for executor with ID 7
21/07/05 00:23:09 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000009 on host slave5 for executor with ID 8
21/07/05 00:23:09 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000010 on host slave6 for executor with ID 9
21/07/05 00:23:09 INFO YarnAllocator: Received 4 containers from YARN, launching executors on 4 of them.
21/07/05 00:23:11 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000011 on host slave4 for executor with ID 10
21/07/05 00:23:11 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000012 on host slave3 for executor with ID 11
21/07/05 00:23:11 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000013 on host slave2 for executor with ID 12
21/07/05 00:23:11 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000014 on host slave1 for executor with ID 13
21/07/05 00:23:11 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000015 on host slave5 for executor with ID 14
21/07/05 00:23:11 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000016 on host slave6 for executor with ID 15
21/07/05 00:23:11 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000017 on host slave4 for executor with ID 16
21/07/05 00:23:11 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000018 on host slave3 for executor with ID 17
21/07/05 00:23:11 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000019 on host slave2 for executor with ID 18
21/07/05 00:23:11 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000020 on host slave1 for executor with ID 19
21/07/05 00:23:11 INFO YarnAllocator: Received 10 containers from YARN, launching executors on 10 of them.
21/07/05 00:23:14 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000021 on host slave5 for executor with ID 20
21/07/05 00:23:14 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000022 on host slave6 for executor with ID 21
21/07/05 00:23:14 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000023 on host slave4 for executor with ID 22
21/07/05 00:23:14 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000024 on host slave3 for executor with ID 23
21/07/05 00:23:14 INFO YarnAllocator: Launching container container_1625415732249_0006_01_000025 on host slave2 for executor with ID 24
21/07/05 00:23:14 INFO YarnAllocator: Received 5 containers from YARN, launching executors on 5 of them.
21/07/05 00:23:41 INFO YarnAllocator: Driver requested a total number of 0 executor(s).
21/07/05 00:23:41 INFO ApplicationMaster$AMEndpoint: Driver terminated or disconnected! Shutting down. spark-client:34143
21/07/05 00:23:41 INFO ApplicationMaster$AMEndpoint: Driver terminated or disconnected! Shutting down. spark-client:34143
21/07/05 00:23:41 INFO ApplicationMaster: Final app status: SUCCEEDED, exitCode: 0
21/07/05 00:23:41 INFO ApplicationMaster: Unregistering ApplicationMaster with SUCCEEDED
21/07/05 00:23:41 INFO AMRMClientImpl: Waiting for application to be successfully unregistered.
21/07/05 00:23:41 INFO ApplicationMaster: Deleting staging directory hdfs://master:9000/user/hadoopuser/.sparkStaging/application_1625415732249_0006
21/07/05 00:23:41 INFO ShutdownHookManager: Shutdown hook called


